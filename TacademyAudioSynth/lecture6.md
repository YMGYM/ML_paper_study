# Vocoder
## 음성 신호의 기초
- 차세대 인터페이스로서의 음성 신호
- 음성 신호 -> 텍스트 : 음성 인식
- 신호를 음성 신호로 변환 : 음성 합성
- 누가 말했는지를 파악하는 과정 : 화자 인식
- 노이즈가 제거된 신호 출력 : 음성 향상


## 음성의 생성
- Voiced, Unvoiced
  

## 디지털 신호처리
- 샘플링 - 양자화
- Nyquist Sampling Theorem : 샘플링 주파수가 2f_max 보다 크기만 하면 완벽히 복원할 수 있다. -> 질문(주파수가 크다는건 더 자주 생플링하는게 맞나.. 그러니까 신호 주파수의 50% 이상은 생플링 해야한다는게 맞는가..?)
- Aliasing : 듬성듬성 샘플링 했을 때 발생하는 현상 : 샘플링 레이트를 올리거나, LP filter 를 통과 (주파수의 최대폭을 줄인다.)
    - Sampling Frequency를 높이면 용량 커짐
    - LP filter - 어느 정도 왜곡된 신호
  
## 푸리에 변환
- 주파수 영역 - Waveform이 특정 주파수 두 개로 분해
- DFT (O(n^2) - 시간이 N개, 주파수 영역이 N개)
- FFT (DFT의 시간복잡도를 개선함) -> 질문 : DTF에서 두 컴포넌트가 어떻게 묶이는건지 알 수 있을까요
- STFT 시간 딘위로 나눠서 주파수 변환
  - 중간중간 오버래핑 되도록 구간 분할

## 스펙토그램
- Phase를 버리고 Amplitude 로만 계산하자
- X : Time, Y : frequency, Color : magnitude

## Mel Scale
- 주파수 대역에 따라 민감도가 다름
- 특정 수식으로 (log 형태 적용)
- mel-scale로 스펙트로그램을 재조정하면 : 멜 스펙토그램이라고 한다.
  
# 보코더의 개념
- 매개 변수를 보내고 수신 측에서 그 매개변수에서 음성을 합성
- 음성 합성이 심플해짐

## 근데 왜 보코더를 사용?
- 음성 신호가 너무 큼...
- 음성 feature 를 뽑고 나중에 음성 신호로 변환함
- 또한 딥러닝은 복소수를 계산할 수 없음
- 다량의 학습 데이터를 통해서 일반화를 할 수 있음 

## Griffin-Lim 알고리즘
- 반복적인 연산을 통하여 phase를 추정하는 알고리즘
- Neural vocoder : 멜 스펙토그램을 입력으로 받아 음성 신호를 생성하는 딥러닝 모델
- 1초 단위로 나뉜 음성 신호를 학습하도록 하여 메모리 사용 부담 줄임